{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10dc7ccd",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Estimation\n",
    "\n",
    "a) Assume we have n positive data points Y1,...,Yn ~ Exponential(theta). Compute the maximum likelihood estimator for theta. \n",
    "\n",
    "b) Assume we have n positive data points Y1,..., Yn ~ Uniform(0, theta), meaning the data is coming from a uniform distribution in the interval [0, theta]. Compute the maximum likelihood estimator for theta. \n",
    "\n",
    "c) Estimate bias, variance, and RMSE for the estimator in (b) when theta = 20 and n = 200 by doing simulations in Python. Don't forget to submit your code for this portion.\n",
    "\n",
    "d) What are the estimated values in (c) if n increases to 1000? Describe your observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395b92ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum Likelihood Estimation - Part A and B attached at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48379d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias:\n",
      "10.710098289860639\n",
      "MSE:\n",
      "119.87715782398321\n",
      "RMSE:\n",
      "10.948842761862242\n",
      "Variance:\n",
      "5.1709524455074245\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Maximum Likelihood Estimator - Part C\n",
    "n = 200\n",
    "theta = 20\n",
    "\n",
    "theta_hats = []\n",
    "for i in range(n):\n",
    "    # Produce a random sample set of size n from a uniform distribution \n",
    "    y_sim_uniform = np.random.uniform(0, theta, n)\n",
    "\n",
    "    # Based on the MLE computed in part (b), theta_hat = y(n)\n",
    "    theta_hat = y_sim_uniform[-1]\n",
    "\n",
    "    # Add the theta_hat of each sample set to the list\n",
    "    theta_hats.append(theta_hat)\n",
    "\n",
    "theta_hats = np.array(theta_hats)\n",
    "\n",
    "# Calculate bias\n",
    "bias = np.mean(theta_hats)\n",
    "print(\"Bias:\")\n",
    "print (bias)\n",
    "\n",
    "mse = np.mean((theta_hats - theta)**2)\n",
    "print(\"MSE:\")\n",
    "print (mse)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\")\n",
    "print(rmse)\n",
    "\n",
    "# Calculate Variance\n",
    "variance = mse - (bias**2)\n",
    "print(\"Variance:\")\n",
    "print (variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9943075a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias:\n",
      "9.839740293695169\n",
      "MSE:\n",
      "137.0134501158347\n",
      "RMSE:\n",
      "11.70527445709133\n",
      "Variance:\n",
      "40.19296106846642\n"
     ]
    }
   ],
   "source": [
    "# Maximum Likelihood Estimator - Part D\n",
    "n = 1000\n",
    "theta = 20\n",
    "\n",
    "theta_hats = []\n",
    "for i in range(1000):\n",
    "    # Produce a random sample set of size n from a uniform distribution \n",
    "    y_sim_uniform = np.random.uniform(0, theta, n)\n",
    "\n",
    "    # Based on the MLE computed in part (b), theta_hat = y(n)\n",
    "    theta_hat = y_sim_uniform[-1]\n",
    "\n",
    "    # Add the theta_hat of each sample set to the list\n",
    "    theta_hats.append(theta_hat)\n",
    "\n",
    "theta_hats = np.array(theta_hats)\n",
    "\n",
    "# Calculate bias\n",
    "bias = np.mean(theta_hats)\n",
    "print(\"Bias:\")\n",
    "print (bias)\n",
    "\n",
    "mse = np.mean((theta_hats - theta)**2)\n",
    "print(\"MSE:\")\n",
    "print (mse)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\")\n",
    "print(rmse)\n",
    "\n",
    "# Calculate Variance\n",
    "variance = mse - (bias**2)\n",
    "print(\"Variance:\")\n",
    "print (variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230c5a89",
   "metadata": {},
   "source": [
    "##### Part D - Describe your observations \n",
    "\n",
    "Based on my observations of Part C and Part D calculations, it seems as though the value of n does not have a direct impact on the calculated values of bias, RMSE, and variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a73be2",
   "metadata": {},
   "source": [
    "## Bootstrap\n",
    "\n",
    "(a) Assume we have a sample of 20 IID data points with the following values: 3.0 1.9 6.4 5.9 4.2 6.2 1.4 2.9 2.3 4.8 7.8 4.5 0.7 4.4 4.4 6.5 7.6 6.1 2.7 1.6\n",
    "\n",
    "Assume we define T as the median among 20 data points. Use bootstrap to estimate the standard error and the confidence interval for T. \n",
    "\n",
    "(b) Use y = np.random.normal(0, 5, 100) to generate 100 data points from the normal distribution N(0, 5). Consider the generated data points as your observed data.\n",
    "\n",
    "* Apply the bootstrap method to estimate the standard error for T1 and T2, where T1 is the sample median and T2 is the maximum value in the sample.\n",
    "* Next, compute the actual standard error for T1 and T2 by simulating many times from the data source (i.e., N(0, 5)).\n",
    "\n",
    "Compare the estimated standard error from the bootstrap with the actual standard error from the simulations. Report your observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6efb5932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True median value of data set y:\n",
      "4.4\n",
      "Standard error of median computed by bootstrap:\n",
      "0.77015491785744\n",
      "95% Confidence interval of median:\n",
      "(2.9339199999999996, 5.866080000000001)\n"
     ]
    }
   ],
   "source": [
    "# Bootstrap - Part A \n",
    "\n",
    "y_sample = [3.0, 1.9, 6.4, 5.9, 4.2, 6.2, 1.4, 2.9, 2.3, 4.8, 7.8, 4.5, 0.7, 4.4, 4.4, 6.5, 7.6, 6.1, 2.7, 1.6]\n",
    "t_ground = np.median(y_sample)\n",
    "print(\"True median value of data set y:\")\n",
    "print(t_ground)\n",
    "\n",
    "# Calculate the standard error using bootstrap\n",
    "t_boot_list = []\n",
    "for b in range(1000):\n",
    "    y_boot = np.random.choice(y_sample, len(y_sample), replace = True)\n",
    "   # print(y_boot)\n",
    "    t_boot = np.median(y_boot)\n",
    "   # print(t_boot)\n",
    "    t_boot_list.append(t_boot)\n",
    "\n",
    "\n",
    "print(\"Standard error of median computed by bootstrap:\")\n",
    "print(np.std(t_boot_list))\n",
    "\n",
    "\n",
    "# Caculate confidence interval \n",
    "\n",
    "def confidence_interval_p(y_list):\n",
    "    n = len(y_list)\n",
    "    p_hat = np.median(y_list)\n",
    "    se_hat = (1/n * p_hat * (1-p_hat))\n",
    "    a = p_hat + 1.96 * se_hat\n",
    "    b = p_hat - 1.96 * se_hat\n",
    "    return a, b\n",
    "\n",
    "print(\"95% Confidence interval of median:\")\n",
    "print(confidence_interval_p(y_sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5e56ee8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Standard error of T1 using bootstrap:\n",
      "0.5157762105604494\n",
      "Estimated Standard Error of T2 using bootstrap:\n",
      "1.1603538876466086\n",
      "Estimated Standard error of T1 using simulation from source:\n",
      "0.6178466353246963\n",
      "Estimated Standard Error of T2 using simulation from source:\n",
      "2.133434606374551\n"
     ]
    }
   ],
   "source": [
    "# Bootstrap - Part B\n",
    "\n",
    "# ESTIMATED STANDARD ERROR\n",
    "# Generate data set for observed data\n",
    "y_observed = np.random.normal(0, 5, 100)\n",
    "\n",
    "# Calculate T1\n",
    "t1_ground = np.median(y_observed)\n",
    "\n",
    "# Calculate T2\n",
    "t2_ground = np.max(y_observed)\n",
    "\n",
    "\n",
    "t1_boot_list = []\n",
    "t2_boot_list = []\n",
    "for b in range(1000):\n",
    "    # Generate a boostrap sample from the observed data, y_observed\n",
    "    y_boot = np.random.choice(y_observed, len(y_observed), replace = True)\n",
    "\n",
    "    # Compute the statistic on the bootstrap sample (i.e. t1 and t2)\n",
    "    t1_boot = np.median(y_boot)\n",
    "    t2_boot = max(y_boot)\n",
    "\n",
    "    t1_boot_list.append(t1_boot)\n",
    "    t2_boot_list.append(t2_boot)\n",
    "    \n",
    "# Estimate the standard error using bootstrap\n",
    "print(\"Estimated Standard error of T1 using bootstrap:\")\n",
    "print(np.std(t1_boot_list))\n",
    "print(\"Estimated Standard Error of T2 using bootstrap:\")\n",
    "print(np.std(t2_boot_list))\n",
    "\n",
    "\n",
    "\n",
    "# ACTUAL STANDARD ERROR\n",
    "t1_sim_list = []\n",
    "t2_sim_list = []\n",
    "\n",
    "for i in range(1000):\n",
    "    # Generate a sample set of data\n",
    "    y_sim = np.random.normal(0, 5, 100)\n",
    "\n",
    "    # Compute the statistic on the sample set\n",
    "    t1_sim = np.median(y_sim)\n",
    "    t2_sim = max(y_sim)\n",
    "\n",
    "    t1_sim_list.append(t1_sim)\n",
    "    t2_sim_list.append(t2_sim)\n",
    "\n",
    "# Estimate the standard error using simulation from source\n",
    "print(\"Estimated Standard error of T1 using simulation from source:\")\n",
    "print(np.std(t1_sim_list))\n",
    "print(\"Estimated Standard Error of T2 using simulation from source:\")\n",
    "print(np.std(t2_sim_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7684d1ae",
   "metadata": {},
   "source": [
    "##### Part D - Describe your observations \n",
    "\n",
    "I'm seeing similar values between the standard error of T1 using bootstrap and simulation (difference tends to be about .1), but the difference between the standard error of T2 using bootstrap and simulation is much higher (difference tends to be about 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3097d53",
   "metadata": {},
   "source": [
    "## Parametric Bootstrap\n",
    "\n",
    "The bootstrap method we discussed in class was the nonparametirc bootstrap method. Here, we try another method called parametirc bootstrap. We use the parametric bootstrap when we can assume a parametric distribution model for the data. Parametric bootstrap can be used to estimate the standard error for parameters in this distribution model. Let's apply the method to our data from the previous problem: 3.0 1.9 6.4 5.9 4.2 6.2 1.4 2.9 2.3 4.8 7.8 4.5 0.7 4.4 4.4 6.5 7.6 6.1 2.7 1.6.\n",
    "\n",
    "(a) First, we need a parametric distribution model for the data. Let's assume the data points in part (a) are generated from a normal distribution with the mean of theta and the standard deviation of 2 (i.e., N(theta, 2)). Using the observed data, compute theta_hat, the estimated value of theta in this distribution model. \n",
    "\n",
    "(b) Generate many samples (20 data points each) from the distribution with the estimated parameter (i.e., N(theta_hat, 2)). \n",
    "\n",
    "(c) In each sample, estimate the value of theta based on the simulated data points.\n",
    "\n",
    "(d) Compute the standard deviation for the estimated parameter among the samples. This standard deviation is the estimated standard error for theta. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c11a6c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Standard error of theta using bootstrap:\n",
      "0.46518326278467936\n",
      "Estimated Standard error of theta using simulation from source:\n",
      "0.4417438655601606\n"
     ]
    }
   ],
   "source": [
    "# Parametric Bootstrap - Part A\n",
    "\n",
    "# Generates 20 data points with normal distribution N(theta, 2)\n",
    "# y = np.random.normal(theta, 2, 20)\n",
    "\n",
    "y_observed = [3.0, 1.9, 6.4, 5.9, 4.2, 6.2, 1.4, 2.9, 2.3, 4.8, 7.8, 4.5, 0.7, 4.4, 4.4, 6.5, 7.6, 6.1, 2.7, 1.6]\n",
    "theta_hat = np.mean(y_observed) \n",
    "\n",
    "t_boot_list = []\n",
    "\n",
    "for b in range(1000):\n",
    "    # Generate a boostrap sample from the observed data, y_observed\n",
    "    y_boot = np.random.choice(y_observed, len(y_observed), replace = True)\n",
    "\n",
    "    # Compute the statistic on the bootstrap sample (i.e. t1 and t2)\n",
    "    t_boot = np.mean(y_boot)\n",
    "\n",
    "    t_boot_list.append(t_boot)\n",
    "    \n",
    "# Estimate the standard error using bootstrap\n",
    "print(\"Estimated Standard error of theta using bootstrap:\")\n",
    "print(np.std(t_boot_list))\n",
    "\n",
    "\n",
    "# Parametric Bootstrap - Part B, C, and D\n",
    "\n",
    "t_sim_list = []\n",
    "\n",
    "for i in range(1000):\n",
    "\n",
    "    # Generate samples of 20 data point each with normal distribution N(theta, 2)\n",
    "    y_sim = np.random.normal(theta_hat, 2, 20)\n",
    "    \n",
    "    # Compute the statistic on the sample set\n",
    "    t_sim = np.mean(y_sim)\n",
    "    \n",
    "    t_sim_list.append(t_sim)\n",
    "\n",
    "# Estimate the standard error using simulation from source\n",
    "print(\"Estimated Standard error of theta using simulation from source:\")\n",
    "print(np.std(t_sim_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a0513f",
   "metadata": {},
   "source": [
    "## Bayesian Inference\n",
    "\n",
    "(a) Assume we have observed IID data points X1, ..., X10 from the distributon N(theta, 1), where the sample average, X bar, is 1.68. If our prior belief about theta can be described by N(0, 3), derive the posterior distribution of theta after observing this data. Compute a point estimate for theta based on the posterior distribution. \n",
    "\n",
    "(b) Assume we have gathered more evidence about theta in part (a) by experimenting with another signal related to the same source and gathering new data points Z1, ..., Z20 ~ N(theta, 4). If Z bar = 0.8, derive the new posterior distribution of theta after seeing both samples. Compute a point estimate for theta based on the posterior distribution. Assume samples in part (a) and (b) are independent from each other. \n",
    "\n",
    "(c) How does your inference result change if your sample in part (b) had more data points?\n",
    "\n",
    "(d) How does your inference change if you had more certainty about your prior belief (i.e. the prior distribution had lower variance)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2e864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian Inference - answers attached"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
